{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1b153d-73a9-42ad-93e1-a12d2f78bc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Constants and Parameters\n",
    "server = \"hdcom1ser.database.windows.net\"\n",
    "database = \"hdcom1\"\n",
    "username = \"serveradminhd\"\n",
    "password = \"A@123456a\"\n",
    "driver = \"{ODBC Driver 18 for SQL Server}\"\n",
    "base_url = \"http://ets.aeso.ca/ets_web/ip/Market/Reports/ActualForecastWMRQHReportServlet\"\n",
    "conn_str = f'DRIVER={driver};SERVER={server};DATABASE={database};UID={username};PWD={password};ncrypt=yes;TrustServerCertificate=no'\n",
    "\n",
    "\n",
    "class DatabaseConnection:\n",
    "    def __init__(self):\n",
    "        self.conn_str = conn_str\n",
    "        self.conn = None\n",
    "\n",
    "    def connect(self):\n",
    "        try:\n",
    "            self.conn = pyodbc.connect(self.conn_str)\n",
    "        except Exception as e:\n",
    "            print(f\"Error connecting to the database: {e}\")\n",
    "\n",
    "    def disconnect(self):\n",
    "        if self.conn:\n",
    "            self.conn.close()\n",
    "            self.conn = None\n",
    "\n",
    "    def execute(self, sql, params=None):\n",
    "        try:\n",
    "            cursor = self.conn.cursor()\n",
    "            if params:\n",
    "                cursor.execute(sql, params)\n",
    "            else:\n",
    "                cursor.execute(sql)\n",
    "            self.conn.commit()\n",
    "        except Exception as e:\n",
    "            print(f\"Error executing SQL query: {e}\")\n",
    "\n",
    "def create_azure_sql_table(connection):\n",
    "    # Drop the table if it exists\n",
    "    drop_table_query = f\"IF OBJECT_ID('historical_demand_data', 'U') IS NOT NULL BEGIN DROP TABLE historical_demand_data END\"\n",
    "    connection.execute(drop_table_query)\n",
    "\n",
    "    create_table_query = f\"CREATE TABLE historical_demand_data (Datetime DATETIME, Forecast_Pool_Price FLOAT, Actual_Posted_Pool_Price FLOAT, Forecast_AIL FLOAT, Actual_AIL FLOAT, Forecast_AIL_and_Actual_AIL_Difference FLOAT)\"\n",
    "    connection.execute(create_table_query)\n",
    "\n",
    "def get_web_page_content(start_timestamp, end_timestamp):\n",
    "    params = {\n",
    "        \"beginDate\": start_timestamp.strftime('%m%d%Y'),\n",
    "        \"endDate\": end_timestamp.strftime('%m%d%Y'),\n",
    "        \"contentType\": \"html\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(base_url, params=params)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            return response.text\n",
    "        else:\n",
    "            print(f'Failed to retrieve data from the website. Status Code: {response.status_code}')\n",
    "            \n",
    "            return None\n",
    "    except requests.RequestException as e:\n",
    "        print(f'An error occurred during the request: {str(e)}')\n",
    "        \n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f'An error occurred while fetching web page content: {str(e)}')\n",
    "        \n",
    "        return None\n",
    "\n",
    "def parse_web_page_content(content):\n",
    "    if content is not None:\n",
    "        soup = BeautifulSoup(content, 'html.parser')\n",
    "        table = soup.find('table', attrs={'border': '1', 'align': 'CENTER'})\n",
    "        \n",
    "        return table\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def extract_data_from_table(table):\n",
    "    if table is not None:\n",
    "        data = []\n",
    "\n",
    "        for row in table.find_all('tr'):\n",
    "            columns = row.find_all('td')\n",
    "            row_data = []\n",
    "\n",
    "            for column in columns:\n",
    "                field = column.text.strip()\n",
    "\n",
    "                if '/' in field:\n",
    "                    field = datetime.strptime(field.replace(' 24', ' 00'), '%m/%d/%Y %H')\n",
    "                else:\n",
    "                    try:\n",
    "                        field = float(field.replace(',', ''))\n",
    "                    except ValueError:\n",
    "                        field = 0\n",
    "\n",
    "                row_data.append(field)\n",
    "            data.append(row_data)\n",
    "\n",
    "        return data\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def scrape_data_to_list(start_timestamp, end_timestamp):\n",
    "    content = get_web_page_content(start_timestamp, end_timestamp)\n",
    "    table = parse_web_page_content(content)\n",
    "    data = extract_data_from_table(table)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def insert_data_to_azure_sql(connection, data, table_name):\n",
    "    if data is not None:\n",
    "        for row_data in data[1:]:\n",
    "            sql = f\"INSERT INTO {table_name} VALUES (?, ?, ?, ?, ?, ?)\"\n",
    "            connection.execute(sql, row_data)\n",
    "\n",
    "        print(f'Data has been saved to {table_name} in Azure SQL Database.')\n",
    "\n",
    "def fetch_data_from_azure_sql(connection, start_timestamp, end_timestamp, table_name):\n",
    "    query = f\"SELECT * FROM {table_name} WHERE Datetime >= ? AND Datetime <= ?\"\n",
    "    data = pd.read_sql_query(query, connection.conn, params=[start_timestamp, end_timestamp])\n",
    "\n",
    "    return data\n",
    "\n",
    "def preprocess_data(data, weather_data):\n",
    "    data['Datetime'] = pd.to_datetime(data['Datetime'])\n",
    "    data = data.merge(weather_data, on='Datetime')\n",
    "    data['Datetime'] = data['Datetime'].astype(int) // 10**9\n",
    "    non_numeric_columns = data.select_dtypes(exclude=['number'])\n",
    "    data = data.drop(non_numeric_columns, axis=1)\n",
    "\n",
    "    return data\n",
    "\n",
    "def train_and_predict_model(data):\n",
    "    X = data.drop(['Actual_Posted_Pool_Price'], axis=1)\n",
    "    y = data['Actual_Posted_Pool_Price']\n",
    "\n",
    "    X_train = X.iloc[:-23]\n",
    "    y_train = y.iloc[:-23]\n",
    "    X_val = X.iloc[-23:]\n",
    "    y_val = y.iloc[-23:]\n",
    "\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "\n",
    "    print(f'Predicted Demand for the Next 24 Hours: {y_pred}')\n",
    "    print(f'Mean Absolute Error: {mae}')\n",
    "    print(f'Root Mean Squared Error: {rmse}')\n",
    "\n",
    "\n",
    "# Main Execution Flow\n",
    "start_timestamp = datetime.now() - relativedelta(years=1)\n",
    "end_timestamp = start_timestamp + timedelta(days=2)\n",
    "\n",
    "connection = DatabaseConnection()\n",
    "connection.connect()\n",
    "\n",
    "create_azure_sql_table(connection)\n",
    "\n",
    "scraped_data = scrape_data_to_list(start_timestamp, end_timestamp)\n",
    "if scraped_data:\n",
    "    insert_data_to_azure_sql(connection, scraped_data, 'historical_demand_data')\n",
    "\n",
    "demand_data = fetch_data_from_azure_sql(connection, start_timestamp, end_timestamp, 'historical_demand_data')\n",
    "weather_data = fetch_data_from_azure_sql(connection, start_timestamp, end_timestamp, 'calgary_weather_data')\n",
    "\n",
    "preprocessed_data = preprocess_data(demand_data, weather_data)\n",
    "train_and_predict_model(preprocessed_data)\n",
    "\n",
    "# Disconnect from the database when done\n",
    "connection.disconnect()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
